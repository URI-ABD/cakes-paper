\section{Datasets And Benchmarks}
\label{sec:datasets-and-benchmarks}

\subsection{ANN-Benchmark Datasets}
\label{sec:datasets-and-benchmarks:ann-benchmark-datasets}

We benchmark on a variety of datasets from the ANN-benchmarks suite~\cite{aumuller2020ann}.
Table~\ref{tab:datasets:summary} summarizes these datasets.
All benchmarks were conducted on an Intel Xeon E5-2690 v4 CPU @ 2.60GHz with 512GB RAM.
The OS kernel was Manjaro Linux 5.15.164-1-MANJARO.
The Rust compiler was Rust 1.83.0, and the Python interpreter version was 3.9.18.

\begin{table}
    \caption{Datasets used in benchmarks.}
    \label{tab:datasets:summary}
    \begin{center}
        \begin{sc}
            \begin{tabular}{|l|l|l|l|}
                \hline
                \textbf{Dataset} & \textbf{Dist. Function}  &\textbf{Card}  & \textbf{Dim}  \\
                \hline
                Fashion-Mnist    & Euclidean                   & 60,000             & 784                    \\
                \hline
                Glove-25         & Cosine                      & 1,183,514          & 25                     \\
                \hline
                Sift             & Euclidean                   & 1,000,000          & 128                    \\
                \hline
                Random           & Euclidean                   & 1,000,000          & 128                    \\
                \hline
                SILVA            & Levenshtein                 & 2,224,640          & 3,712         \\
                \hline
                RadioML          & Dynamic Time Warping        & 97,920             & 1,024                  \\
                \hline
            \end{tabular}
        \end{sc}
    \end{center}
    \vskip -0.1in
\end{table}

\subsection{Random Datasets and Synthetic Augmentation}
\label{sec:datasets-and-benchmarks:random-datasets}

In addition to benchmarks on datasets from the ANN-Benchmarks suite, we also benchmarked on synthetic augmentations of these real datasets, using the process described in \ref{sec:methods:synthetic-data}.
In particular, we use a noise tolerance $\epsilon = 0.01$ and explore the scaling behavior as the cardinality multiplier (referred to as ``Mult.'' in Tables~\ref{tab:results:qps-and-recall-fmn},~\ref{tab:results:qps-and-recall-glove},~\ref{tab:results:qps-and-recall-sift} and~\ref{tab:results:qps-and-recall-random}) increases.
We also benchmarked on purely randomly-generated datasets of various cardinalities.
For this, we used a base cardinality of 1,000,000 and a dimensionality of 128 to match the Sift dataset; hereafter, we refer to the random dataset with cardinality 1,000,000 and dimensionality 128 as ``Random.''
This benchmark allows us to isolate the effect of a manifold structure (which we expect to be absent in a purely random dataset) on the performance of the CAKES' algorithms.

In order to calculate recall on the augmented datasets, we perform linear search in Rust and save the results to disk.
We verified that linear search on the original dataset produced neighbors with perfect recall compared to those provided by the ANN-Benchmarks suite.
We then use the results of linear search on the augmented datasets as ground truth for calculating recall of CAKES's algorithms in Rust and read them in Python for calculating recall of HNSW, ANNOY, and FAISS-IVF.


\subsection{SILVA 18S}
\label{sec:datasets-and-benchmarks:silva-18s}

To demonstrate CAKES with a more exotic distance function, we also benchmarked on the SILVA 18S ribosomal RNA dataset~\cite{10.1093/nar/gks1219}.
This dataset contains ribosomal RNA sequences of 2,224,640 genomes, with the longest sequence having 3,712 letters.
We held out a set of 1,000 random sequences from the dataset to use as queries for benchmarking.
We use Levenshtein~\cite{levenshtein1966binary} distance on the unaligned sequences to build the tree and to perform $k$-NN search.
We note that the sequences in this dataset were provided in a multiple sequence alignment with a width of 50,000 characters.
We could have used Hamming distance on the aligned sequences, but we chose to use Levenshtein distance on the unaligned sequences to help demonstrate the flexibility of CAKES in handling exotic distance functions.
Under Hamming distance, we could consider this dataset to have an embedding dimension of 50,000, but for Levenshtein distance, we state the dimensionality as the length of the longest sequence, i.e.\, 3,712.


\subsection{Radio ML}
\label{sec:datasets-and-benchmarks:radio-ml}

As another example of an exotic distance function, we benchmarked CAKES on the Radio-ML dataset~\cite{oshea2018radioml} under Dynamic Time Warping~\cite{muller2007dynamic} as the distance function.
This dataset contains samples of synthetically generated signal captures of different modulation modes over a range of signal-to-noise ratio (SNR) levels.
Specifically, it comprises 24 modulation modes at 26 different SNRs ranging from -20 dB to 30 dB, with 4,096 samples at each combination of modulation mode and SNR level.
Thus, it contains $24 \cdot 26 \cdot 4096 = 2,555,504$ samples in total.
Each sample is a 1,024-dimensional complex-valued vector, representing a signal capture (a time-series of complex-valued numbers).
We used a subset of this dataset, containing $97,304$ samples at 10dB SNR and used another $1,000$ samples at the same SNR as a hold-out set of queries.


\subsection{Other Algorithms}
\label{sec:datasets-and-benchmarks:other-algorithms}

We benchmarked the three CAKES algorithms against a na\"ive linear search implementation in Rust.
We also benchmarked against three state-of-the-art similarity search algorithms: HNSW, ANNOY, and FAISS-IVF in Python.
We verified that our implementation of linear search produces the same neighbors as provided by the ANN-Benchmarks suite for Fashion-MNIST, Glove-25 and Sift datasets.
We then used this linear search implementation to find and store the ground-truth for the augmented versions of the datasets.
We used this ground-truth to calculate recall for CAKES's algorithms in Rust and for HNSW, ANNOY, and FAISS-IVF in Python.
We plot the results of these benchmarks in Figure~\ref{fig:results:scaling-plots}.
