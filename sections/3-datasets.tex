\section{Datasets And Benchmarks}
\label{sec:datasets-and-benchmarks}

\subsection{ANN-Benchmark Datasets}
\label{sec:datasets-and-benchmarks:ann-benchmark-datasets}

We benchmark on a variety of datasets from the ANN-benchmarks suite~\cite{aumuller2020ann}.
Table~\ref{tab:datasets:summary} summarizes the cardinality and dimensionality of each these datasets.
All benchmarks were conducted on an Intel Xeon E5-2690 v4 CPU @ 2.60GHz with 512GB RAM.
The OS kernel was Manjaro Linux 5.15.164-1-MANJARO.
The Rust compiler was Rust 1.83.0, and the Python interpreter version was 3.9.18.

\begin{table}
    \caption{Datasets used in benchmarks.}
    \label{tab:datasets:summary}
    \begin{center}
        \begin{sc}
            \begin{tabular}{|l|l|l|l|}
                \hline
                \textbf{Dataset} & \textbf{Dist. Function}  &\textbf{Card}  & \textbf{Dim}  \\
                \hline
                Fashion-Mnist    & Euclidean                   & 60,000             & 784                    \\
                \hline
                Glove-25         & Cosine                      & 1,183,514          & 25                     \\
                \hline
                Sift             & Euclidean                   & 1,000,000          & 128                    \\
                \hline
                Random           & Euclidean                   & 1,000,000          & 128                    \\
                \hline
                SILVA            & Levenshtein                 & 2,224,640          & 3,712         \\
                \hline
                RadioML          & Dynamic Time Warping        & 97,920             & 1,024                  \\
                \hline
            \end{tabular}
        \end{sc}
    \end{center}
    \vskip -0.1in
\end{table}

\subsection{Random Datasets and Synthetic Augmentation}
\label{sec:datasets-and-benchmarks:random-datasets}

In addition to benchmarks on datasets from the ANN-Benchmarks suite, we also benchmarked on synthetic augmentations of these real datasets, using the process described in \ref{sec:methods:synthetic-data}.
In particular, we use a noise tolerance $\epsilon = 0.01$ and explore the scaling behavior as the cardinality multiplier (referred to as ``Mult.'' in Tables~\ref{tab:results:qps-and-recall-fmn},~\ref{tab:results:qps-and-recall-glove},~\ref{tab:results:qps-and-recall-sift} and~\ref{tab:results:qps-and-recall-random}) increases.
We also benchmarked on purely randomly-generated datasets of various cardinalities.
For this, we used a base cardinality of 1,000,000 and a dimensionality of 128 to match the Sift dataset; hereafter, we refer to the random dataset with cardinality 1,000,000 and dimensionality 128 as ``Random.''
This benchmark allows us to isolate the effect of a manifold structure (which we expect to be absent in a purely random dataset) on the performance of the CAKES' algorithms.

In order to calculate recall on the augmented datasets, we perform linear search in Rust and save the results to disk.
We verified that linear search on the original dataset produced neighbors with perfect recall compared to those provided by the ANN-Benchmarks suite.
We then use the results of linear search on the augmented datasets as ground truth for calculating recall of CAKES's algorithms in Rust and read them in Python for calculating recall of HNSW, ANNOY, and FAISS-IVF.


\subsection{SILVA 18S}
\label{sec:datasets-and-benchmarks:silva-18s}

To demonstrate CAKES with a more exotic distance function, we also benchmarked on the SILVA 18S ribosomal RNA dataset~\cite{10.1093/nar/gks1219}.
This dataset contains ribosomal RNA sequences of 2,224,640 genomes, with the longest sequence having 3,712 letters.
We held out a set of 1,000 random sequences from the dataset to use as queries for benchmarking.
We use Levenshtein~\cite{levenshtein1966binary} distance on the unaligned sequences to build the tree and to perform $k$-NN search.
We note that the sequences in this dataset were provided in a multiple sequence alignment with a width of 50,000 characters.
We could have used Hamming distance on the aligned sequences, but we chose to use Levenshtein distance on the unaligned sequences to help demonstrate the flexibility of CAKES in handling exotic distance functions.
Under Hamming distance, we could consider this dataset to have an embedding dimension of 50,000, but for Levenshtein distance, we state the dimensionality as the length of the longest sequence, i.e.\, 3,712.


\subsection{Radio ML}
\label{sec:datasets-and-benchmarks:radio-ml}

As another example of an exotic distance function, we benchmarked CAKES on the Radio-ML dataset~\cite{oshea2018radioml} under Dynamic Time Warping~\cite{muller2007dynamic} as the distance function.
This dataset contains samples of synthetically generated signal captures of different modulation modes over a range of signal-to-noise ratio (SNR) levels.
Specifically, it comprises 24 modulation modes at 26 different SNRs ranging from -20 dB to 30 dB, with 4,096 samples at each combination of modulation mode and SNR level.
Thus, it contains $24 \cdot 26 \cdot 4096 = 2,555,504$ samples in total.
Each sample is a 1,024-dimensional complex-valued vector, representing a signal capture (a time-series of complex-valued numbers).
We used a subset of this dataset, containing $97,304$ samples at 10dB SNR and used another $1,000$ samples at the same SNR as a hold-out set of queries.

% \subsection{Local Fractal Dimension}
% \label{sec:dayasets:lfd-of-datasets}

% Since the CAKES algorithms were designed to scale in time with the LFD of the dataset, we examine the LFD of each dataset we used for benchmarks.
% Figure~\ref{fig:results:lfd-plots} illustrates the trends in LFD for Fashion-MNIST, Glove-25, Sift, Random, Silva 18S, and Radio-ML.
% In this section, when we discuss trends in LFD, unless otherwise noted, we are referring to the 95$^{th}$ percentile of LFD.

% For the Fashion-MNIST dataset we observe in Figure~\ref{fig:results:fashion-mnist-lfd} that until approximately depth 5, Fashion-MNIST's LFD is low (i.e., less than 4).
% It then starts increasing, reaching a peak of about 6 near depth 20, before decreasing to 1 at the maximum depth.

% Relative to Fashion-MNIST, Glove-25 has low LFD, as shown in Figure~\ref{fig:results:glove-25-lfd}.
% In particular, Glove-25's LFD is less than 3 for all depths.

% Figure~\ref{fig:results:sift-lfd} shows the LFD by depth for Sift, which has higher LFD relative to Fashion-MNIST and Glove-25.
% It increases sharply to a peak of 9 around a depth of 10, after which it decreases smoothly until reaching the deepest leaves in the tree.

% We contrast the low LFD of Sift with that of the Random dataset which has the same cardinality and dimension. As shown in Figure~\ref{fig:results:random-lfd}, the character of this dataset is very different from the others.
% The LFD starts at 20 at depth 0 and all percentile lines decrease linearly with depth until reaching the leaves of the tree.
% The spread in LFD starts very small for the first few clusters and increases as depth increases.

% The Silva dataset, shown in Figure~\ref{fig:results:silva-lfd}, exhibits consistently low LFD.
% In particular, LFD is less than 3 for all depths, hovering near 1 for clusters at depth 40 and deeper.

% For the Radio-ML dataset, the LFD values show three distinct peaks around an LFD of 12 at or near depths of 8, 25 and 50.
% Each peak is followed by a linear decrease until encountering a sharp spike for the next peak.
% Within each of the tree portions, this dataset has a character similar to that of the Random dataset.
% This suggests that the dataset obeys the manifold hypothesis at some scales, but that it is not ``scale free,'' as the LFD varies significantly by depth.
% This is likely the result of a piecewise uniform sampling strategy used to generate the different modulation modes present in the dataset.

\subsection{Other Algorithms}
\label{sec:datasets-and-benchmarks:other-algorithms}

We benchmarked the three CAKES algorithms against a na\"ive linear search implementation in Rust.
We also benchmarked against three state-of-the-art similarity search algorithms: HNSW, ANNOY, and FAISS-IVF in Python.
We verified that our implementation of linear search produces the same neighbors as provided by the ANN-Benchmarks suite for Fashion-MNIST, Glove-25 and Sift datasets.
We then used this linear search implementation to find and store the ground-truth for the augmented versions of the datasets.
We used this ground-truth to calculate recall for CAKES's algorithms in Rust and for HNSW, ANNOY, and FAISS-IVF in Python.
We plot the results of these benchmarks in Figure~\ref{fig:results:scaling-plots}.
